{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 1: analysis of natural language using string objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Hi my name is Kristoffer, how are you?\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "wd = os.getcwd()\n",
    "fileobjects = sorted(os.listdir(wd + \"/DATA\"))\n",
    "fname = fileobjects[1]\n",
    "with open(\"DATA/\" + fname, 'r') as f:\n",
    "    s = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "content = re.sub(r\"\\d\",\"\",s)\n",
    "content = content.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = re.compile(r\"\\W+\")\n",
    "unigrams = tokenizer.split(content)\n",
    "\n",
    "clean_unigrams = []\n",
    "for unigram in unigrams:\n",
    "    if len(unigram) > 1:\n",
    "        clean_unigrams.append(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labmt = pd.read_csv('TOOLS/labmt_dict.csv',sep='\\t', encoding='utf-8', index_col=0)\n",
    "labmt.head()\n",
    "\n",
    "avg = labmt.happiness_average.mean()\n",
    "sent_dict = (labmt.happiness_average - avg).to_dict()\n",
    "\n",
    "sent_vec = []\n",
    "for unigram in clean_unigrams:\n",
    "    sent_vec.append(sent_dict.get(unigram,0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(sent_vec)\n",
    "ax.axhline(y = np.mean(sent_vec), c=\"r\",linewidth=1)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Sentiment')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicer(input, n = 100, cut_off = False):\n",
    "    \"\"\"\n",
    "    slice tokenized text in slices of n tokens\n",
    "    - end cut off for full length normalization\n",
    "    \"\"\"\n",
    "    slices = []\n",
    "    for i in range(0,len(input),n):\n",
    "        slices.append(input[i:(i+n)])\n",
    "    if cut_off:\n",
    "        del slices[-1]\n",
    "    return slices\n",
    "\n",
    "slices = slicer(clean_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(unigrams):\n",
    "    labmt = pd.read_csv('TOOLS/labmt_dict.csv',sep='\\t', encoding='utf-8', index_col=0)\n",
    "    avg = labmt.happiness_average.mean()\n",
    "    sent_dict = (labmt.happiness_average - avg).to_dict()\n",
    "    sent_vec = []\n",
    "    for unigram in unigrams:\n",
    "        sent_vec.append(sent_dict.get(unigram,0.0))\n",
    "    return(sent_vec)\n",
    "\n",
    "sent_vec = []\n",
    "for slc in slices:\n",
    "    sent_vec.append(sum(sentiment_score(slc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(sent_vec)\n",
    "ax.axhline(y = np.mean(sent_vec), c=\"r\",linewidth=1)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Sentiment (sliced)')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(l, n = 5):\n",
    "    \"\"\"moving average filter with window size n\"\"\"\n",
    "    sigma = 0\n",
    "    res = list( 0 for x in l)\n",
    "    for i in range(0 , n):\n",
    "        sigma = sigma + l[i]\n",
    "        res[i] = sigma / (i + 1)\n",
    "    for i in range( n, len(l) ):\n",
    "        sigma = sigma - l[i - n] + l[i]\n",
    "        res[i] = sigma / n\n",
    "    return res\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(smooth(sent_vec))\n",
    "ax.axhline(y = np.mean(smooth(sent_vec, n = 10)), c=\"r\",linewidth=1)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Sentiment (sliced)')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swc",
   "language": "python",
   "name": "myswc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
