{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector space models of text collections #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's build a corpus of social media stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello world', 'have a good day', 'hello all', 'how are you', 'hello and have a nice day']\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"hello world\",\n",
    "          \"have a good day\",\n",
    "          \"hello all\",\n",
    "          \"how are you\",\n",
    "          \"hello and have a nice day\"]\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 10, 'world': 9, 'good': 4, 'day': 3, 'hello': 6, 'how': 7, 'are': 2, 'and': 1, 'all': 0, 'have': 5, 'nice': 8}\n"
     ]
    }
   ],
   "source": [
    "transform_corpus = CountVectorizer().fit(corpus)\n",
    "print(transform_corpus.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bag-of-words representation of our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 6)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 10)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 3)\t1\n",
      "  (4, 5)\t1\n",
      "  (4, 6)\t1\n",
      "  (4, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorspace_sparse = transform_corpus.transform(corpus)\n",
    "print(vectorspace_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 0 1 1 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0 1]\n",
      " [0 1 0 1 0 1 1 0 1 0 0]]\n",
      "\n",
      "Word-level word count [1 1 1 2 1 2 3 1 1 1 1]\n",
      "\n",
      "Document-level word count [2 3 2 3 5]\n",
      "\n",
      "number of words in our corpus = 15\n"
     ]
    }
   ],
   "source": [
    "print(vectorspace_sparse.toarray())\n",
    "print()\n",
    "print(\"Word-level word count {}\".format(vectorspace_sparse.toarray().sum(axis = 0)))\n",
    "print()\n",
    "print(\"Document-level word count {}\".format(vectorspace_sparse.toarray().sum(axis = 1)))\n",
    "print()\n",
    "print(\"number of words in our corpus = {}\".format(sum(vectorspace_sparse.toarray().sum(axis = 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
